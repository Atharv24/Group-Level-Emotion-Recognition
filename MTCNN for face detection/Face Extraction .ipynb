{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#needs to be updated for exception handling from other pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src import detect_faces, show_bboxes\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_path = '../Dataset/emotiw/'\n",
    "\n",
    "processed_dataset_path = '../Dataset/FaceCoordinates/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_transforms = {\n",
    "#     'train' : transforms.Compose([transforms.ToPILImage()]),\n",
    "    \n",
    "#     'val' : transforms.Compose([transforms.ToPILImage()])\n",
    "# }\n",
    "\n",
    "\n",
    "# image_datasets = {x : datasets.ImageFolder(os.path.join(dataset_path, x), data_transforms[x])\n",
    "#                     for x in ['train', 'val']}\n",
    "\n",
    "image_datasets = {x : datasets.ImageFolder(os.path.join(dataset_path, x))\n",
    "                    for x in ['train', 'val']}\n",
    "\n",
    "# dataloaders = { x : torch.utils.data.DataLoader(image_datasets[x], batch_size = 1, shuffle=True, num_workers= 4)\n",
    "#                    for x in ['train', 'val']}\n",
    "\n",
    "# dataset_sizes = {x : len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Negative', 'Neutral', 'Positive']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# type(train_data[0:5])\n",
    "\n",
    "# # neg_images = []\n",
    "# # neutral_images = []\n",
    "# # pos_images = []\n",
    "# # for i in range(len(image_datasets['train'])):\n",
    "# #     label = image_datasets['train'][i][1]\n",
    "# #     if label == 0:\n",
    "# #         neg_images.append(image_datasets['train'][i][0])\n",
    "# #         print('neg')\n",
    "# #     elif label == 1:\n",
    "# #         neutral_images.append(image_datasets['train'][i][0])\n",
    "# #         print('neut')\n",
    "# #     else:\n",
    "# #         pos_images.append(image_datasets['train'][i][0])\n",
    "# #         print('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neg_images = 2758\n",
    "# neut_images = 3080\n",
    "# pos_images = 3997\n",
    "\n",
    "# train_neg = image_datasets['train'][0:neg_images][0]\n",
    "# train_neut = image_datasets['train'][neg_images: neg_images + neut_images][0]\n",
    "# train_pos = image_datasets['train'][neg_images + neut_images : -1][0]\n",
    "\n",
    "# val_neg = image_datasets['val'][0:neg_images][0]\n",
    "# val_neut = image_datasets['val'][neg_images: neg_images + neut_images][0]\n",
    "# val_pos = image_datasets['val'][neg_images + neut_images : -1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_dataset = image_datasets['train']\n",
    "validation_dataset = image_datasets['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_train = sorted(os.listdir(dataset_path + 'train/Negative/'))\n",
    "neu_train = sorted(os.listdir(dataset_path + 'train/Neutral/'))\n",
    "pos_train = sorted(os.listdir(dataset_path + 'train/Positive/'))\n",
    "\n",
    "neg_val = sorted(os.listdir(dataset_path + 'val/Negative/'))\n",
    "neu_val = sorted(os.listdir(dataset_path + 'val/Neutral/'))\n",
    "pos_val = sorted(os.listdir(dataset_path + 'val/Positive/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_train_filelist = [x.split('.')[0] for x in neg_train]\n",
    "neu_train_filelist = [x.split('.')[0] for x in neu_train]\n",
    "pos_train_filelist = [x.split('.')[0] for x in pos_train]\n",
    "\n",
    "neg_val_filelist = [x.split('.')[0] for x in neg_val]\n",
    "neu_val_filelist = [x.split('.')[0] for x in neu_val]\n",
    "pos_val_filelist = [x.split('.')[0] for x in pos_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg_1', 'neg_10', 'neg_100', 'neg_1000', 'neg_1001', 'neg_1002', 'neg_1003', 'neg_1004', 'neg_1005', 'neg_1006']\n",
      "['neu_1', 'neu_10', 'neu_100', 'neu_1000', 'neu_1001', 'neu_1002', 'neu_1003', 'neu_1004', 'neu_1005', 'neu_1006']\n",
      "['pos_1', 'pos_10', 'pos_100', 'pos_1000', 'pos_1001', 'pos_1002', 'pos_1003', 'pos_1004', 'pos_1005', 'pos_1006']\n",
      "['neg_1', 'neg_10', 'neg_100', 'neg_1000', 'neg_1001', 'neg_1002', 'neg_1003', 'neg_1004', 'neg_1005', 'neg_1006']\n",
      "['neu_1', 'neu_10', 'neu_100', 'neu_1000', 'neu_1001', 'neu_1002', 'neu_1003', 'neu_1004', 'neu_1005', 'neu_1006']\n",
      "['pos_1', 'pos_10', 'pos_100', 'pos_1000', 'pos_1001', 'pos_1002', 'pos_1003', 'pos_1004', 'pos_1005', 'pos_1006']\n"
     ]
    }
   ],
   "source": [
    "print(neg_train_filelist[:10])\n",
    "print(neu_train_filelist[:10])\n",
    "print(pos_train_filelist[:10])\n",
    "\n",
    "print(neg_val_filelist[:10])\n",
    "print(neu_val_filelist[:10])\n",
    "print(pos_val_filelist[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_filelist = neg_train_filelist + neu_train_filelist + pos_train_filelist\n",
    "val_filelist = neg_val_filelist + neu_val_filelist + pos_val_filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pos_train_count = 0\n",
    "# neg_train_count = 0\n",
    "# neut_train_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9815\n",
      "4346\n"
     ]
    }
   ],
   "source": [
    "print(len(training_dataset))\n",
    "print(len(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#No faces detected for pos_928. Empty file stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(training_dataset)):\n",
    "# for i in range(5):\n",
    "    image, label = training_dataset[i]\n",
    "    print(train_filelist[i])\n",
    "    try:\n",
    "        bounding_boxes, landmarks = detect_faces(image)\n",
    "        if bounding_boxes.size == 0:\n",
    "            print('MTCNN model handling empty face condition at ' + train_filelist[i])\n",
    "        if label == 0:\n",
    "            np.savez(processed_dataset_path + 'train/Negative/' + train_filelist[i] , a=bounding_boxes, b=landmarks)\n",
    "#             neg_train_count = neg_train_count + 1\n",
    "        elif label == 1:\n",
    "            np.savez(processed_dataset_path + 'train/Neutral/' + train_filelist[i] , a=bounding_boxes, b=landmarks)\n",
    "#             neut_train_count += 1\n",
    "        else:\n",
    "            np.savez(processed_dataset_path + 'train/Positive/' + train_filelist[i] , a=bounding_boxes, b=landmarks)\n",
    "#             pos_train_count += 1\n",
    "#         if i % 100 == 0:\n",
    "#             print(i)\n",
    "            \n",
    "            \n",
    "    except ValueError:\n",
    "        print('No faces detected for ' + train_filelist[i] + \". Also MTCNN failed.\")\n",
    "        if label == 0:\n",
    "#             print('File ' + train_filelist[i] + \" empty\")\n",
    "            np.savez(processed_dataset_path + 'train/Negative/' + train_filelist[i] , a=np.zeros(1), b=np.zeros(1))\n",
    "#             neg_train_count += 1\n",
    "        elif label == 1:\n",
    "#             print('File ' + train_filelist[i] + \" empty\")\n",
    "            np.savez(processed_dataset_path + 'train/Neutral/' + train_filelist[i] , a=np.zeros(1), b=np.zeros(1))\n",
    "#             neut_train_count += 1\n",
    "        else:\n",
    "#             print('File ' + train_filelist[i] + \" empty\")\n",
    "            np.savez(processed_dataset_path + 'train/Positive/' + train_filelist[i] , a=np.zeros(1), b=np.zeros(1))\n",
    "#             pos_train_count += 1\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_1\n",
      "neg_10\n",
      "neg_100\n",
      "MTCNN model handling empty face condition at neg_100\n",
      "neg_1000\n",
      "neg_1001\n",
      "neg_1002\n",
      "neg_1003\n",
      "neg_1004\n",
      "neg_1005\n",
      "neg_1006\n",
      "neg_1007\n",
      "neg_1008\n",
      "neg_1009\n",
      "MTCNN model handling empty face condition at neg_1009\n",
      "neg_101\n",
      "neg_1010\n",
      "neg_1011\n",
      "neg_1012\n",
      "neg_1013\n",
      "neg_1014\n",
      "MTCNN model handling empty face condition at neg_1014\n",
      "neg_1015\n",
      "neg_1016\n",
      "neg_1017\n",
      "neg_1018\n",
      "neg_1019\n",
      "neg_102\n",
      "neg_1020\n",
      "neg_1021\n",
      "neg_1022\n",
      "neg_1023\n",
      "neg_1024\n",
      "neg_1025\n",
      "neg_1026\n",
      "neg_1027\n",
      "neg_1028\n",
      "neg_1029\n",
      "neg_103\n",
      "neg_1030\n",
      "neg_1031\n",
      "neg_1032\n",
      "neg_1033\n",
      "neg_1034\n",
      "neg_1035\n",
      "neg_1036\n",
      "neg_1037\n",
      "neg_1038\n",
      "neg_1039\n",
      "neg_104\n",
      "neg_1040\n",
      "neg_1041\n",
      "neg_1042\n",
      "neg_1043\n",
      "neg_1044\n",
      "neg_1045\n",
      "neg_1046\n",
      "neg_1047\n",
      "neg_1048\n",
      "neg_1049\n",
      "neg_105\n",
      "neg_1050\n",
      "neg_1051\n",
      "neg_1052\n",
      "neg_1053\n",
      "neg_1054\n",
      "neg_1055\n",
      "neg_1056\n",
      "neg_1057\n",
      "neg_1058\n",
      "neg_1059\n",
      "neg_106\n",
      "neg_1060\n",
      "neg_1061\n",
      "neg_1062\n",
      "neg_1063\n",
      "neg_1064\n",
      "neg_1065\n",
      "neg_1066\n",
      "neg_1067\n",
      "neg_1068\n",
      "neg_1069\n",
      "neg_107\n",
      "neg_1070\n",
      "neg_1071\n",
      "neg_1072\n",
      "neg_1073\n",
      "neg_1074\n",
      "neg_1075\n",
      "neg_1076\n",
      "neg_1077\n",
      "neg_1078\n",
      "neg_1079\n",
      "neg_108\n",
      "neg_1080\n",
      "neg_1081\n",
      "neg_1082\n",
      "neg_1083\n",
      "neg_1084\n",
      "neg_1085\n",
      "neg_1086\n",
      "neg_1087\n",
      "neg_1088\n",
      "neg_1089\n",
      "neg_109\n",
      "neg_1090\n",
      "neg_1091\n",
      "neg_1092\n",
      "neg_1093\n",
      "neg_1094\n",
      "neg_1095\n",
      "neg_1096\n",
      "neg_1097\n",
      "neg_1098\n",
      "neg_1099\n",
      "neg_11\n",
      "neg_110\n",
      "neg_1100\n",
      "neg_1101\n",
      "neg_1102\n",
      "neg_1103\n",
      "neg_1104\n",
      "neg_1105\n",
      "neg_1106\n",
      "neg_1107\n",
      "neg_1108\n",
      "neg_1109\n",
      "neg_111\n",
      "neg_1110\n",
      "neg_1111\n",
      "neg_1112\n",
      "neg_1113\n",
      "neg_1114\n",
      "neg_1115\n",
      "neg_1116\n",
      "neg_1117\n",
      "neg_1118\n",
      "neg_1119\n",
      "neg_112\n",
      "neg_1120\n",
      "neg_1121\n",
      "neg_1122\n",
      "neg_1123\n",
      "neg_1124\n",
      "neg_1125\n",
      "neg_1126\n",
      "neg_1127\n",
      "neg_1128\n",
      "neg_1129\n",
      "neg_113\n",
      "neg_1130\n",
      "neg_1131\n",
      "neg_1132\n",
      "neg_1133\n",
      "neg_1134\n",
      "neg_1135\n",
      "neg_1136\n",
      "neg_1137\n",
      "neg_1138\n",
      "neg_1139\n",
      "neg_114\n",
      "neg_1140\n",
      "neg_1141\n",
      "neg_1142\n",
      "neg_1143\n",
      "neg_1144\n",
      "neg_1145\n",
      "neg_1146\n",
      "neg_1147\n",
      "neg_1148\n",
      "neg_1149\n",
      "neg_115\n",
      "neg_1150\n",
      "neg_1151\n",
      "neg_1152\n",
      "neg_1153\n",
      "neg_1154\n",
      "neg_1155\n",
      "neg_1156\n",
      "neg_1157\n",
      "neg_1158\n",
      "neg_1159\n",
      "neg_116\n",
      "neg_1160\n",
      "neg_1161\n",
      "neg_1162\n",
      "neg_1163\n",
      "neg_1164\n",
      "neg_1165\n",
      "neg_1166\n",
      "neg_1167\n",
      "neg_1168\n",
      "neg_1169\n",
      "neg_117\n",
      "neg_1170\n",
      "neg_1171\n",
      "neg_1172\n",
      "neg_1173\n",
      "neg_1174\n",
      "neg_1175\n",
      "neg_1176\n",
      "neg_1177\n",
      "neg_1178\n",
      "neg_1179\n",
      "neg_118\n",
      "neg_1180\n",
      "neg_1181\n",
      "neg_1182\n",
      "neg_1183\n",
      "neg_1184\n",
      "neg_1185\n",
      "neg_1186\n",
      "neg_1187\n",
      "neg_1188\n",
      "neg_1189\n",
      "neg_119\n",
      "neg_1190\n",
      "neg_1191\n",
      "neg_1192\n",
      "neg_1193\n",
      "neg_1194\n",
      "neg_1195\n",
      "neg_1196\n",
      "neg_1197\n",
      "neg_1198\n",
      "neg_1199\n",
      "neg_12\n",
      "neg_120\n",
      "neg_1200\n",
      "neg_1201\n",
      "neg_1202\n",
      "neg_1203\n",
      "neg_1204\n",
      "neg_1205\n",
      "neg_1206\n",
      "neg_1207\n",
      "neg_1208\n",
      "neg_1209\n",
      "neg_121\n",
      "neg_1210\n",
      "neg_1211\n",
      "neg_1212\n",
      "neg_1213\n",
      "neg_1214\n",
      "neg_1215\n",
      "neg_1216\n",
      "neg_1217\n",
      "neg_1218\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(validation_dataset)):\n",
    "# for i in range(5):\n",
    "    image, label = validation_dataset[i]\n",
    "    print(val_filelist[i])\n",
    "    try:\n",
    "        bounding_boxes, landmarks = detect_faces(image)\n",
    "        if bounding_boxes.size == 0:\n",
    "            print('MTCNN model handling empty face condition at ' + val_filelist[i])\n",
    "        if label == 0:\n",
    "            np.savez(processed_dataset_path + 'val/Negative/' + val_filelist[i] , a=bounding_boxes, b=landmarks)\n",
    "#             neg_val_count = neg_val_count + 1\n",
    "        elif label == 1:\n",
    "            np.savez(processed_dataset_path + 'val/Neutral/' + val_filelist[i] , a=bounding_boxes, b=landmarks)\n",
    "#             neut_val_count += 1\n",
    "        else:\n",
    "            np.savez(processed_dataset_path + 'val/Positive/' + val_filelist[i] , a=bounding_boxes, b=landmarks)\n",
    "#             pos_val_count += 1\n",
    "#         if i % 100 == 0:\n",
    "#             print(i)\n",
    "            \n",
    "            \n",
    "    except ValueError:\n",
    "        print('No faces detected for ' + val_filelist[i] + \". Also MTCNN failed.\")\n",
    "        if label == 0:\n",
    "#             print('File ' + val_filelist[i] + \" empty\")\n",
    "            np.savez(processed_dataset_path + 'val/Negative/' + val_filelist[i] , a=np.zeros(1), b=np.zeros(1))\n",
    "#             neg_val_count += 1\n",
    "        elif label == 1:\n",
    "#             print('File ' + val_filelist[i] + \" empty\")\n",
    "            np.savez(processed_dataset_path + 'val/Neutral/' + val_filelist[i] , a=np.zeros(1), b=np.zeros(1))\n",
    "#             neut_val_count += 1\n",
    "        else:\n",
    "#             print('File ' + val_filelist[i] + \" empty\")\n",
    "            np.savez(processed_dataset_path + 'val/Positive/' + val_filelist[i] , a=np.zeros(1), b=np.zeros(1))\n",
    "#             pos_val_count += 1\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# img = Image.open('images/office1.jpg')\n",
    "# bounding_boxes, landmarks = detect_faces(img)\n",
    "# # show_bboxes(img, bounding_boxes, landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# type(bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bounding_boxes, landmarks = detect_faces(image_datasets['train'][7][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "        bbox_ld = np.load('../Dataset/FaceFeatures/train/Negative/neg_' + str(i + 1) + '.npz')\n",
    "        bbox = bbox_ld['a']\n",
    "#         landmarks = bbox_ld['b']\n",
    "        if bbox.size == 0:\n",
    "            print(bbox.shape, i + 1)\n",
    "#             print(landmarks.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bboxes, landmarks = detect_faces(image_datasets['train'][457][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_datasets['train'][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_bboxes(image_datasets['train'][457][0], bboxes, landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloaders['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(os.listdir('../Dataset/emotiw/train/Negative/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(a == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
